<!doctype html><html class=no-js lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>Performance and Deployments - Intel Launches Cooper Lake: 3rd Generation Xeon Scalable for 4P/8P Ser - WebBlog</title><script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content="As part of the discussion points, Intel stated that it has integrated its BF16 support into its usual array of supported frameworks and utilities that it normally defines as Intel DL Boost. This includes PyTorch, TensorFlow, OneAPI, OpenVino, and ONNX. We had a discussion with Wei Li, who heads up Intels AI Software Group at"><meta name=robots content="index,follow,noarchive"><meta property="og:title" content="Performance and Deployments - Intel Launches Cooper Lake: 3rd Generation Xeon Scalable for 4P/8P Ser"><meta property="og:description" content="As part of the discussion points, Intel stated that it has integrated its BF16 support into its usual array of supported frameworks and utilities that it normally defines as Intel DL Boost. This includes PyTorch, TensorFlow, OneAPI, OpenVino, and ONNX. We had a discussion with Wei Li, who heads up Intels AI Software Group at"><meta property="og:type" content="article"><meta property="og:url" content="/intel-launches-cooper-lake-3rd-generation-xeon-scalable-for-4p8p-servers.html"><meta property="article:section" content="post"><meta property="article:published_time" content="2024-02-27T00:00:00+00:00"><meta property="article:modified_time" content="2024-02-27T00:00:00+00:00"><meta itemprop=name content="Performance and Deployments - Intel Launches Cooper Lake: 3rd Generation Xeon Scalable for 4P/8P Ser"><meta itemprop=description content="As part of the discussion points, Intel stated that it has integrated its BF16 support into its usual array of supported frameworks and utilities that it normally defines as Intel DL Boost. This includes PyTorch, TensorFlow, OneAPI, OpenVino, and ONNX. We had a discussion with Wei Li, who heads up Intels AI Software Group at"><meta itemprop=datePublished content="2024-02-27T00:00:00+00:00"><meta itemprop=dateModified content="2024-02-27T00:00:00+00:00"><meta itemprop=wordCount content="589"><meta itemprop=keywords content><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=https://assets.cdnweb.info/hugo/mainroad/css/style.css><link rel="shortcut icon" href=./favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class=logo><a class=logo__link href=./index.html title=WebBlog rel=home><div class="logo__item logo__text"><div class=logo__title>WebBlog</div></div></a></div><div class=divider></div></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>Performance and Deployments - Intel Launches Cooper Lake: 3rd Generation Xeon Scalable for 4P/8P Ser</h1><div class="post__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2024-02-27T00:00:00Z>February 27, 2024</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=./categories/blog/ rel=category>blog</a></span></div></div></header><div class="content post__content clearfix"><h2>Performance and Deployments</h2><p>As part of the discussion points, Intel stated that it has integrated its BF16 support into its usual array of supported frameworks and utilities that it normally defines as ‘Intel DL Boost’. This includes PyTorch, TensorFlow, OneAPI, OpenVino, and ONNX. We had a discussion with Wei Li, who heads up Intel’s AI Software Group at Intel, who confirmed to us that all these libraries have already been updated for use with BF16.&nbsp; For the high level programmers, these libraries will accept FP32 data and do the data conversion automatically to BF16, however the functions will still require an indication to use BF16 over INT8 or something similar.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/15862/3rd%20Gen%20Xeon_Cooper%20Lake%20Press%20Slides_EMBARGO%206-18-20_0600PT-page-013_575px.jpg style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>When speaking with Wei Li, he confirmed that all the major CSPs who have taken delivery of Cooper Lake are already porting workloads onto BF16, and have been for quite some time. That isn’t to say that BF16 is suitable for every workload, but it provides a balance between the accuracy of FP32 and the computational speed of FP16. As noted in the slide above, over FP32, BF16 implementations are achieving up to ~1.9x speedups on both training and inference with Intel’s various CSP customers.</p><p>Normally we don’t post too many graphs of first party performance numbers, however I did want to add this one.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/15862/3rd%20Gen%20Xeon_Cooper%20Lake%20Press%20Slides_EMBARGO%206-18-20_0600PT-page-015_575px.jpg style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>Here we see Intel’s BF16 DL Boost at work for Resnet-50 in both training and inference. Resnet-50 is an old training set at this point, but is still used as a reference point for performance given its limited scope in layers and convolutions. Here Intel is showing a 72% increase in performance with Cooper Lake in BF16 mode vs Cooper Lake in FP32 mode when training the dataset.</p><p>Inference is a bit different, because inference can take advantage of lower bit, high bandwidth data casting, such as INT8, INT4, and such. Here we see BF16 still giving 1.8x performance over normal FP32 AVX512, but INT8 has that throughput advantage. This is a balance of speed and accuracy.</p><p>It should be noted that this graph also includes software optimizations over time, not only raw performance of the same code across multiple platforms.</p><p>I would like to point out the standard FP32 performance generation on generation. For AI Training, Intel is showing a 1.82/1.64 = 11% gain, while for inference we see a 2.04/1.95 = 4.6 % gain in performance generation-on-generation. Given that Cooper uses the same cores underneath as Cascade, this is mostly due to core frequency increases as well as bandwidth increases.</p><h3><strong>Deployments</strong></h3><p>A number of companies reached out to us in advance of the launch to tell us about their systems.</p><p>Lenovo will be announcing the launch of its ThinkSystem SR860 V2 and SR850 V2 servers with Cooper Lake and Optane DCPMM. The SR860 V2 will support up to four double-wide 300W GPUs in a dual socket configuration.</p><p><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/15862/ThinkSystem%20SR860%20V2%20Interior%20Rear%202%20processor_575px.jpg style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>The fact that Lenovo is offering 2P variants of Cooper Lake is quite puzzling, especially as Intel said these were aimed at 4P systems and up. Hopefully we can get one in for testing.</p><p>Also, GIGABYTE is announcing its R292-4S0 and R292-4S1 servers, both quad socket.</p><p><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/15862/R292-4S0_575px.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>One of Intel’s partners stated to us that they were not expecting Cooper Lake to launch so soon – even within the next quarter. As a result, they were caught off guard and had to scramble to get materials for this announcement. It would appear that Intel had a need to pull in this announcement to now, perhaps because one of the major CSPs is ready to announce.</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7orrAp5utnZOde6S7zGiqoaenZH52hJVrZqKmpJq5brjArqWcoJWoeqS7zqmcq2WclrimeZKrm2aflaOys63ToqanZaiavK950pyYpZmSobJuss6rZG2oaKV6tLHRr5yrq19o</p></div></article></main><nav class="pager flex"><div class="pager__item pager__item--prev"><a class=pager__link href=./120mm-radiator-fan-roundup-part-2-fan-harder.html rel=prev><span class=pager__subtitle>«&#8201;Previous</span><p class=pager__title>Testing Methodology - 120mm Radiator Fan Roundup Part 2: Fan Harder</p></a></div><div class="pager__item pager__item--next"><a class=pager__link href=./chance-rapper-wife-good-carnival.html rel=next><span class=pager__subtitle>Next&#8201;»</span><p class=pager__title>Chance The Rapper &amp;amp; Wife Are All Good Despite Carnival Scandal</p></a></div></nav></div><aside class=sidebar><div class="widget-recent widget"><h4 class=widget__title>Recent Posts</h4><div class=widget__content><ul class=widget__list><li class=widget__item><a class=widget__link href=./bella-lambert-net-worth-2024.html>Bella Lambert Net Worth 2024</a></li><li class=widget__item><a class=widget__link href=./what-is-the-difference-between-crucible-tongs-and-beaker-tongs-html.html>What is the difference between crucible tongs and Beaker tongs?</a></li><li class=widget__item><a class=widget__link href=./who-is-esco-jouley-everything-to-know-about-the-actress.html>Who Is Esco Jouley? Everything To Know About The Actress</a></li><li class=widget__item><a class=widget__link href=./who-joyce-randolph-tied-the-knot-with-exploring-the-identity-of-richard-lincoln-charles-html.html>Who Joyce Randolph Tied the Knot With? Exploring the Identity of Richard Lincoln Charles</a></li><li class=widget__item><a class=widget__link href=./john-legend-chrissy-teigen-relationship.html>John Legend and Chrissy Teigens Enduring Love Story</a></li></ul></div></div><div class="widget-categories widget"><h4 class=widget__title>Categories</h4><div class=widget__content><ul class=widget__list><li class=widget__item><a class=widget__link href=./categories/blog/>blog</a></li></ul></div></div></aside></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2024 WebBlog.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=https://assets.cdnweb.info/hugo/mainroad/js/menu.js></script>
<script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/floating.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>